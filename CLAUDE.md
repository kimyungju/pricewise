# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

LangGraph autonomous agent that searches for products via Tavily and returns structured Pydantic output (Receipt). Features conversation summarization and human-in-the-loop CLI approval.

## Tech Stack

Python 3.12+, uv (package manager), LangGraph, LangChain, OpenAI (gpt-4o), Tavily, Pydantic v2

## Commands

```bash
# Install dependencies
uv sync

# Run the agent
uv run python main.py

# Run all tests
uv run pytest -v

# Run a single test file
uv run pytest tests/test_schemas.py -v

# Run a single test
uv run pytest tests/test_schemas.py::test_receipt_defaults -v

# Run async tests (middleware tests)
uv run pytest tests/test_middleware.py -v  # requires pytest-asyncio
```

## Architecture

Uses `src/` layout: package is `src/pricewise/`.

- **`agent.py`** — Builds the LangGraph agent via `create_react_agent`. This is the central orchestration point that wires together the model, tools, middleware hooks, and checkpointer.
- **`schemas.py`** — Pydantic models: `ProductQuery`, `PriceComparisonQuery`, `ReviewQuery`, `BudgetQuery`/`BudgetItem` (tool inputs) and `Receipt` (structured agent output via `response_format`).
- **`tools/_client.py`** — Shared Tavily client factory (`get_tavily`), response parser (`parse_tavily_response`), and result formatter (`format_results`). All Tavily-based tools import from here.
- **`tools/search_product.py`** — Searches for products via Tavily.
- **`tools/compare_prices.py`** — Compares prices across retailers via Tavily.
- **`tools/get_reviews.py`** — Fetches product reviews and ratings via Tavily.
- **`tools/calculate_budget.py`** — Pure computation: totals, tax, budget check. No API calls.
- **`middleware/summarization.py`** — Factory `create_summarization_hook(model, max_messages)` returns an async `pre_model_hook` that compresses history via LLM when messages exceed threshold.
- **`middleware/human_approval.py`** — CLI `prompt_for_approval()` helper used in the execution loop when the graph hits `interrupt_before=["tools"]`.
- **`main.py`** — Async entrypoint. Handles the invoke → check interrupt → approve → resume loop with `InMemorySaver` checkpointing.

## Key LangGraph Patterns

- Agent is built with `create_react_agent` (not legacy `AgentExecutor`)
- Summarization uses `pre_model_hook` returning `{"llm_input_messages": ...}` to avoid mutating state
- HITL uses `interrupt_before=["tools"]` + `agent.aget_state()` to check `state.next` + resume with `ainvoke(None, config)`
- Structured output uses `response_format=Receipt`, accessed via `result["structured_response"]`
- Model initialized with `init_chat_model("gpt-4o", model_provider="openai")` for provider flexibility

## Environment

Requires `.env` file with `OPENAI_API_KEY` and `TAVILY_API_KEY`. See `.env.example`.

- `CHECKPOINT_POSTGRES_URI` — PostgreSQL connection string (required unless `USE_MEMORY_SAVER=true`)
- `USE_MEMORY_SAVER` — Set to `true` to use InMemorySaver instead of Postgres (default: `false`)

## Design Docs

Implementation plan and design rationale in `docs/plans/`.

## Commit Message Rules

- **No AI attribution:** Never include "Co-authored by Claude Code," "Generated by AI," or any equivalent metadata in commit messages.
- **Conciseness:** Keep commit messages brief, focusing only on the essential changes.
- **Cleanliness:** Ensure the message appears as if written manually by a human developer.